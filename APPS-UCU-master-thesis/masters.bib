@article{ZophL16,
  author    = {Barret Zoph and
               Quoc V. Le},
  title     = {Neural Architecture Search with Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.01578},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01578},
  archivePrefix = {arXiv},
  eprint    = {1611.01578},
  timestamp = {Mon, 13 Aug 2018 16:46:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZophL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{2017arXiv170404110S,
       author = {{Salinas}, David and {Flunkert}, Valentin and {Gasthaus}, Jan},
        title = "{DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2017",
        month = "Apr",
          eid = {arXiv:1704.04110},
        pages = {arXiv:1704.04110},
archivePrefix = {arXiv},
       eprint = {1704.04110},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170404110S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2019arXiv190511946T,
       author = {{Tan}, Mingxing and {Le}, Quoc V.},
        title = "{EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2019",
        month = "May",
          eid = {arXiv:1905.11946},
        pages = {arXiv:1905.11946},
archivePrefix = {arXiv},
       eprint = {1905.11946},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190511946T},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Baker2016DesigningNN,
  title={Designing Neural Network Architectures using Reinforcement Learning},
  author={Bowen Baker and Otkrist Gupta and Nikhil Naik and Ramesh Raskar},
  journal={ArXiv},
  year={2016},
  volume={abs/1611.02167}
}

@InProceedings{pmlr-v97-ying19a,
    title =     {{NAS}-Bench-101: Towards Reproducible Neural Architecture Search},
    author =    {Ying, Chris and Klein, Aaron and Christiansen, Eric and Real, Esteban and Murphy, Kevin and Hutter, Frank},
    booktitle = {Proceedings of the 36th International Conference on Machine Learning},
    pages =     {7105--7114},
    year =      {2019},
    editor =    {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
    volume =    {97},
    series =    {Proceedings of Machine Learning Research},
    address =   {Long Beach, California, USA},
    month =     {09--15 Jun},
    publisher = {PMLR},
    url =       {http://proceedings.mlr.press/v97/ying19a.html}
    }
    
@article{tilmann,
author = {Gneiting, Tilmann and Balabdaoui, Fadoua and Raftery, Adrian E.},
title = {Probabilistic forecasts, calibration and sharpness},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},

volume = {69},
number = {2},
pages = {243-268},
keywords = {Cross-validation, Density forecast, Ensemble prediction system, Ex post evaluation, Forecast verification, Model diagnostics, Posterior predictive assessment, Predictive distribution, Prequential principle, Probability integral transform, Proper scoring rule},
doi = {10.1111/j.1467-9868.2007.00587.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2007.00587.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2007.00587.x},
abstract = {Summary.â Probabilistic forecasts of continuous variables take the form of predictive densities or predictive cumulative distribution functions. We propose a diagnostic approach to the evaluation of predictive performance that is based on the paradigm of maximizing the sharpness of the predictive distributions subject to calibration. Calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize. Sharpness refers to the concentration of the predictive distributions and is a property of the forecasts only. A simple theoretical framework allows us to distinguish between probabilistic calibration, exceedance calibration and marginal calibration. We propose and study tools for checking calibration and sharpness, among them the probability integral transform histogram, marginal calibration plots, the sharpness diagram and proper scoring rules. The diagnostic approach is illustrated by an assessment and ranking of probabilistic forecasts of wind speed at the Stateline wind energy centre in the US Pacific Northwest. In combination with cross-validation or in the time series context, our proposal provides very general, nonparametric alternatives to the use of information criteria for model diagnostics and model selection.},
year = {2007}
}

@article{CIFAR,
author = {Krizhevsky, Alex},
year = {2012},
month = {05},
pages = {},
title = {Learning Multiple Layers of Features from Tiny Images},
journal = {University of Toronto}
}

@article{Thomas15a,
  author    = {Philip S. Thomas},
  title     = {A Notation for Markov Decision Processes},
  journal   = {CoRR},
  volume    = {abs/1512.09075},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.09075},
  archivePrefix = {arXiv},
  eprint    = {1512.09075},
  timestamp = {Mon, 13 Aug 2018 16:47:19 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Thomas15a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Auer2002,
author="Auer, Peter
and Cesa-Bianchi, Nicol{\`o}
and Fischer, Paul",
title="Finite-time Analysis of the Multiarmed Bandit Problem",
journal="Machine Learning",
year="2002",
month="May",
day="01",
volume="47",
number="2",
pages="235--256",
abstract="Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support.",
issn="1573-0565",
doi="10.1023/A:1013689704352",
url="https://doi.org/10.1023/A:1013689704352"
}

@article{MnihKSGAWR13,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  archivePrefix = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MnihKSGAWR13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article         { lecun-89c,
original =    "orig/lecun-89c.tiff",
author  =       "LeCun, Y. and Jackel,  L. D. and Boser, B.  and Denker, J. S.  and Graf, H. P. and Guyon, I. and Henderson, D. and Howard, R. E. and Hubbard, W.",
title   =        "Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning",
journal =        "IEEE Communication",
year    =        "1989",
month   =        "November",
pages   =        "41-46",
note    =        "invited paper"
}